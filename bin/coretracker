#!/usr/bin/env python

# CoreTracker Copyright (C) 2016  Emmanuel Noutahi
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.

# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.

import argparse
import glob
import logging
import os
import random
import sys
import traceback
from collections import defaultdict as ddict
from math import log10

from Bio import SeqIO
from ete3 import Tree
from yaml import load

from coretracker import __author__, __version__, date
from coretracker.classifier import *
from coretracker.classifier import MODELPATH
from coretracker.classifier.models import ModelType
from coretracker.coreutils import *
from coretracker.settings import *

ENABLE_PAR = True
CPU_COUNT = 0
try:
    from multiprocessing import cpu_count
    CPU_COUNT = cpu_count()
    from joblib import Parallel, delayed
except ImportError:
    try:
        from sklearn.externals.joblib import Parallel, delayed
    except:
        ENABLE_PAR = False

try:
    from yaml import CLoader as Loader
except ImportError:
    from yaml import Loader

etiquette = ["fitch", "suspected", "Fisher pval", "Gene frac",
             "N. rea", "N. used", "Cod. count", "Sub. count",
             "G. len", "codon_lik", "N. mixte", "id"]  # , 'total_aa']


def testing_a_lot(args, settings):
    t = random.randint(30, 90)
    time.sleep(t)
    return [settings.EXCLUDE_AA, settings.AA_MAJORITY_THRESH, settings.FREQUENCY_THRESHOLD,
            settings.GENETIC_CODE, settings.COUNT_THRESHOLD, settings.LIMIT_TO_SUSPECTED_SPECIES]


def AlignmentProgramType(program):
    # Raise a value error if not conform to expected programs
    tmp = program.strip().split()[0]
    if tmp not in ['muscle', 'mafft']:
        raise argparse.ArgumentTypeError(
            "Accepted alignment programs are mafft and muscle")
    else:
        return program


def set_coretracker(args, settings):
    """Set all data for coretracker from the argument list"""
    # Check mafft command input
    progcmd = lambda x: x + ' --auto' if x == 'mafft' else x

    if args.debug:
        logging.basicConfig(level=logging.DEBUG)

    if args.outdir:
        if not os.path.exists(args.outdir):
            os.makedirs(args.outdir)
            # let original error handling
        settings.OUTDIR = args.outdir

    msaprg = progcmd(args.align)

    input_alignment = args.seq
    use_tree = None
    specietree = Tree(args.tree)

    if args.usetree:
        if args.align != 'mafft':
            logging.warning("Cannot usetree with muscle alignment")
        else:
            use_tree = args.tree

    settings.SCALE = args.scale
    hmmfiles = {}
    if args.hmmdir:
        try:
            hfiles = glob.glob(os.path.join(args.hmmdir, '*'))
            for f in hfiles:
                genename = os.path.basename(f).split('.hmm')[0]
                hmmfiles[genename] = f
        except:
            pass

    clf = Classifier.load_from_file(MODELPATH % settings.MODEL_TYPE)
    model = ModelType(settings.MODEL_TYPE, etiquette)

    if clf is None or not clf.trained:
        raise ValueError("Classifier not found or not trained!")

    seqloader = SequenceLoader(input_alignment, args.dnaseq, settings, args.gapfilter, has_stop=args.hasstop,
                               use_tree=use_tree, refine_alignment=args.refine, msaprog=msaprg, hmmdict=hmmfiles)

    # create sequence set
    setseq = SequenceSet(seqloader, specietree, settings.GENETIC_CODE)
    setseq.prot_filtering(args.idfilter, args.gapfilter,
                          args.iccontent, args.rmconst)

    reafinder = ReaGenomeFinder(setseq, settings)
    reafinder.get_genomes()
    reafinder.possible_aa_reassignation()
    return reafinder, clf, model


def compile_result(x, clf, cod_align, model):
    """compile result from analysis"""
    reafinder, fitch, data = x
    s_complete_data = utils.makehash()
    s_complete_data['aa'][fitch.ori_aa1][fitch.dest_aa1] = data
    s_complete_data['genome'] = reafinder.reassignment_mapper['genome']
    X_data, X_labels, _ = read_from_json(
        s_complete_data, None, use_global=False)
    # extract usefull features
    X_data, X_dataprint, selected_et = model.format_data(X_data)
    pred_prob = clf.predict_proba(X_data)
    pred = clf.predict(X_data)
    sppval, outdir, rkp, codvalid = utils.get_report(
        fitch, data, reafinder, cod_align, (X_data, X_labels, pred_prob, pred))
    utils.print_data_to_txt(os.path.join(outdir, fitch.ori_aa + "_to_" + fitch.dest_aa + "_data.txt"),
                            selected_et, X_dataprint, X_labels, pred, pred_prob, sppval, fitch.dest_aa, valid=codvalid)
    return rkp

if __name__ == '__main__':

    # argument parser
    parser = argparse.ArgumentParser(
        description='CoreTracker, A codon reassignment tracker')

    parser.add_argument(
        '--wdir', '--outdir', dest="outdir", default="output", help="Working directory")

    parser.add_argument('--version', action='version', version='%(prog)s 1.0')

    parser.add_argument('--gapfilter', '--gap', type=float, default=0.6, dest='gapfilter',
                        help="Remove position with gap from the alignment, using gapfilter as threshold (default :0.6)")

    parser.add_argument('--idfilter', '--id', type=float, default=0.5, dest='idfilter',
                        help="Conserve only position with at least idfilter residue identity (default : 0.5)")

    parser.add_argument('--icfilter', '--ic', type=float, default=0.5, dest='iccontent',
                        help="Shannon entropy threshold (default : 0.5 ). This will be used to discard column where IC < max(IC_INFO_VECTOR)*(IC_INFO_THRESHOLD/ 100.0)))")

    parser.add_argument('-t', '--intree', dest="tree",
                        help='Input specietree in newick format', required=True)

    parser.add_argument('--scale', type=float, default=1.0,
                        dest='scale', help="Scale to compute the branch format for the '--treein' option of mafft. If you're unsure, use the default value. See http://mafft.cbrc.jp/alignment/software/treein.html")

    parser.add_argument('--protseq', '--prot', '-p', dest='seq',
                        help="Protein sequence input in fasta format", required=True)

    parser.add_argument('--dnaseq', '--dna', '-n', dest='dnaseq',
                        help="Nucleotides sequences input in fasta format", required=True)

    parser.add_argument('--stopcodon', dest='hasstop', action='store_true',
                        help="Whether or not stop are present in protein alignment and dna sequences.")

    parser.add_argument('--debug', dest='debug', action='store_true',
                        help="Enable debug printing")

    parser.add_argument('--rmconst', dest='rmconst', action='store_true',
                        help="Remove constant site from filtered alignment. ")

    parser.add_argument('--norefine', dest='refine', action='store_false',
                        help="Do not refine the alignment. By default the alignment will be refined. This option should never be used if you have made your own multiple alignment and concatenate it. Else you will have absurd alignment (TO FIX)")

    parser.add_argument('--novalid', dest='valid', action='store_false',
                        help="Do not validate prediction by retranslating and checking alignment improvement")

    parser.add_argument('--align', dest='align', nargs='?', type=AlignmentProgramType, const="muscle",
                        help="Choose a program to align your sequences")

    parser.add_argument('--use_tree', dest='usetree', action="store_true",
                        help="This is helpfull only if the mafft alignment is selected. Perform multiple alignment, using species tree as guide tree. The tree must be rooted and binary")

    parser.add_argument('--expos', '--export_position', dest='expos', action="store_true",
                        help="Export a json file with the position of each reassignment in the corresponding genome.")

    parser.add_argument('--hmmdir', dest='hmmdir',
                        help="Link a directory with hmm files for alignment. Each hmmfile should be named in the following format : genename.hmm")

    parser.add_argument('--params', dest='params',
                        help="Use A parameter file to load parameters. If a parameter is not set, the default will be used")

    parser.add_argument('--parallel', dest='parallel', nargs='?', const=CPU_COUNT, type=int, default=0,
                        help="Use Parallelization during execution for each reassignment. This does not guarantee an increase in speed. CPU count will be used if no argument is provided")

    parser.add_argument('--imformat', dest='imformat', choices=('pdf', 'png', 'svg'), default="pdf",
                        help="Image format to use for output (Codon_data file)")

    print("CoreTracker v:%s Copyright (C) %s %s" %
          (__version__, date, __author__))

    args = parser.parse_args()
    setting = Settings()

    paramfile = args.params
    ad_params = {}
    if paramfile:
        with open(paramfile) as f:
            ad_params = load(f, Loader=Loader)

    # setting.set(OUTDIR=args.outdir)  # this does nothing
    setting.fill(ad_params)
    setting.update_params(COMPUTE_POS=args.expos)
    setting.update_params(VALIDATION=args.valid)
    setting.update_params(IMAGE_FORMAT=args.imformat)
    parallel = args.parallel
    reafinder, clf, model = set_coretracker(args, setting)
    codon_align, fcodon_align = reafinder.seqset.get_codon_alignment()
    cod_align = SeqIO.to_dict(fcodon_align)
    reafinder.set_rea_mapper()

    done = False
    results = []
    if args.parallel > 0 and ENABLE_PAR:
        results = Parallel(n_jobs=args.parallel, verbose=2)(delayed(compile_result)(
            x, clf, cod_align, model) for x in reafinder.run_analysis(codon_align, fcodon_align))
        done = True
    elif args.parallel > 0:
        logging.warning(
            "Joblib requirement not found! Disabling parallelization")

    if not done:
        for x in reafinder.run_analysis(codon_align, fcodon_align):
            results.append(compile_result(x, clf, cod_align, model))

    if args.valid and args.expos and results:
        rea_pos_keeper = ddict(dict)
        for r in results:
            for cuspec, readt in r.items():
                for k in readt.keys():
                    rea_pos_keeper[cuspec][k] = readt[k]
        exp_outfile = os.path.join(reafinder.settings.OUTDIR, "positions.json")
        reafinder.export_position(rea_pos_keeper, exp_outfile)

    reafinder.save_all(True)
